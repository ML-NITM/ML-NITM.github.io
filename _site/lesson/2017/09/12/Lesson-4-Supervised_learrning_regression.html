<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Lesson-5: Supervised Learning -- Regression Analysis</title>
  <meta name="description" content="Supervised Learning – Regression Analysis">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/lesson/2017/09/12/Lesson-4-Supervised_learrning_regression.html">
  <link rel="alternate" type="application/rss+xml" title="Introduction to Machine Learning with Python" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">Introduction to Machine Learning with Python</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/books/">Books</a>
            
          
            
            
          
            
            
            <a class="page-link" href="/resources/">Resources</a>
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Lesson-5: Supervised Learning -- Regression Analysis</h1>
    <p class="post-meta">
      <time datetime="2017-09-12T01:31:56+05:30" itemprop="datePublished">
        
        Sep 12, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h1 id="supervised-learning--regression-analysis">Supervised Learning – Regression Analysis</h1>

<p>In regression we are trying to predict a continuous output variable – in contrast to the nominal variables we were predicting in the previous classification examples.</p>

<p>Let’s start with a simple toy example with one feature dimension (explanatory variable) and one target variable. We will create a dataset out of a sine curve with some noise:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>   <span class="c"># -3 : start , 3-Stop, 100: number of points</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>[-3.         -2.93939394 -2.87878788 -2.81818182 -2.75757576 -2.6969697
 -2.63636364 -2.57575758 -2.51515152 -2.45454545 -2.39393939 -2.33333333
 -2.27272727 -2.21212121 -2.15151515 -2.09090909 -2.03030303 -1.96969697
 -1.90909091 -1.84848485 -1.78787879 -1.72727273 -1.66666667 -1.60606061
 -1.54545455 -1.48484848 -1.42424242 -1.36363636 -1.3030303  -1.24242424
 -1.18181818 -1.12121212 -1.06060606 -1.         -0.93939394 -0.87878788
 -0.81818182 -0.75757576 -0.6969697  -0.63636364 -0.57575758 -0.51515152
 -0.45454545 -0.39393939 -0.33333333 -0.27272727 -0.21212121 -0.15151515
 -0.09090909 -0.03030303  0.03030303  0.09090909  0.15151515  0.21212121
  0.27272727  0.33333333  0.39393939  0.45454545  0.51515152  0.57575758
  0.63636364  0.6969697   0.75757576  0.81818182  0.87878788  0.93939394
  1.          1.06060606  1.12121212  1.18181818  1.24242424  1.3030303
  1.36363636  1.42424242  1.48484848  1.54545455  1.60606061  1.66666667
  1.72727273  1.78787879  1.84848485  1.90909091  1.96969697  2.03030303
  2.09090909  2.15151515  2.21212121  2.27272727  2.33333333  2.39393939
  2.45454545  2.51515152  2.57575758  2.63636364  2.6969697   2.75757576
  2.81818182  2.87878788  2.93939394  3.        ]
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">'o'</span><span class="p">);</span>
</code></pre>
</div>

<p><img src="/images/06.Supervised_Learning-Regression-Bernard_files/06.Supervised_Learning-Regression-Bernard_5_0.png" alt="png" /></p>

<h1 id="linear-regression">Linear Regression</h1>

<p>The first model that we will introduce is the so-called simple linear regression. Here, we want to fit a line to the data, which</p>

<p>One of the simplest models again is a linear one, that simply tries to predict the data as lying on a line. One way to find such a line is <code class="highlighter-rouge">LinearRegression</code> (also known as <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares"><em>Ordinary Least Squares (OLS)</em></a> regression).
The interface for LinearRegression is exactly the same as for the classifiers before, only that <code class="highlighter-rouge">y</code> now contains float values, instead of classes.</p>

<p>As we remember, the scikit-learn API requires us to provide the target variable (<code class="highlighter-rouge">y</code>) as a 1-dimensional array; scikit-learn’s API expects the samples (<code class="highlighter-rouge">X</code>) in form a 2-dimensional array – even though it may only consist of 1 feature. Thus, let us convert the 1-dimensional <code class="highlighter-rouge">x</code> NumPy array into an <code class="highlighter-rouge">X</code> array with 2 axes:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Before: '</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">'After: '</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Before:  (100,)
After:  (100, 1)
</code></pre>
</div>

<p>Again, we start by splitting our dataset into a training (75%) and a test set (25%):</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre>
</div>

<p>Next, we use the learning algorithm implemented in <code class="highlighter-rouge">LinearRegression</code> to <strong>fit a regression model to the training data</strong>:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">regressor</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</code></pre>
</div>

<p>After fitting to the training data, we paramerterized a linear regression model with the following values.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Weight coefficients: '</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'y-axis intercept: '</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Weight coefficients:  [ 0.90662492]
y-axis intercept:  0.527378950118
</code></pre>
</div>

<p>Since our regression model is a linear one, the relationship between the target variable (y) and the feature variable (x) is defined as</p>

<p><script type="math/tex">y = weight \times x + \text{intercept}</script>.</p>

<p>Plugging in the min and max values into thos equation, we can plot the regression fit to our training data:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">min_pt</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span> <span class="o">*</span> <span class="n">regressor</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">regressor</span><span class="o">.</span><span class="n">intercept_</span>
<span class="n">max_pt</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">*</span> <span class="n">regressor</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">regressor</span><span class="o">.</span><span class="n">intercept_</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">X</span><span class="o">.</span><span class="nb">max</span><span class="p">()],</span> <span class="p">[</span><span class="n">min_pt</span><span class="p">,</span> <span class="n">max_pt</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s">'o'</span><span class="p">);</span>
</code></pre>
</div>

<p><img src="/images/06.Supervised_Learning-Regression-Bernard_files/06.Supervised_Learning-Regression-Bernard_16_0.png" alt="png" /></p>

<p>Similar to the estimators for classification, we use the <code class="highlighter-rouge">predict</code> method to predict the target variable. And we expect these predicted values to fall onto the line that we plotted previously:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"data"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"prediction"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">X</span><span class="o">.</span><span class="nb">max</span><span class="p">()],</span> <span class="p">[</span><span class="n">min_pt</span><span class="p">,</span> <span class="n">max_pt</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'fit'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x7f5134f579b0&gt;
</code></pre>
</div>

<p><img src="/images/06.Supervised_Learning-Regression-Bernard_files/06.Supervised_Learning-Regression-Bernard_19_1.png" alt="png" /></p>

<p>As we can see in the plot above, the line is able to capture the general slope of the data, but not many details.</p>

<p>Next, let’s try the test set:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"data"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"prediction"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">X</span><span class="o">.</span><span class="nb">max</span><span class="p">()],</span> <span class="p">[</span><span class="n">min_pt</span><span class="p">,</span> <span class="n">max_pt</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'fit'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">);</span>
</code></pre>
</div>

<p><img src="/images/06.Supervised_Learning-Regression-Bernard_files/06.Supervised_Learning-Regression-Bernard_23_0.png" alt="png" /></p>

<p>Again, scikit-learn provides an easy way to evaluate the prediction quantitatively using the <code class="highlighter-rouge">score</code> method. For regression tasks, this is the R<sup>2</sup> score. Another popular way would be the Mean Squared Error (MSE). As its name implies, the MSE is simply the average squared difference over the predicted and actual target values</p>

<script type="math/tex; mode=display">MSE = \frac{1}{n} \sum_{i=1}^{n} (\text{predicted}_i - \text{true}_i)^2</script>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">regressor</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>0.78094571218071562
</code></pre>
</div>

<h1 id="kneighborsregression">KNeighborsRegression</h1>
<p>As for classification, we can also use a neighbor based method for regression. We can simply take the output of the nearest point, or we could average several nearest points. This method is less popular for regression than for classification, but still a good baseline.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="n">kneighbor_regression</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kneighbor_regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=1, p=2,
          weights='uniform')
</code></pre>
</div>

<p>Again, let us look at the behavior on training and test set:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">kneighbor_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"data"</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">,</span> <span class="s">'s'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"prediction"</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">);</span>
</code></pre>
</div>

<p><img src="/images/06.Supervised_Learning-Regression-Bernard_files/06.Supervised_Learning-Regression-Bernard_29_0.png" alt="png" /></p>

<p>On the training set, we do a perfect job: each point is its own nearest neighbor!</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">kneighbor_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"data"</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">,</span> <span class="s">'s'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"prediction"</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">);</span>
</code></pre>
</div>

<p><img src="/images/06.Supervised_Learning-Regression-Bernard_files/06.Supervised_Learning-Regression-Bernard_31_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">kneighbor_regression</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>0.93296629159871636
</code></pre>
</div>

<h1 id="compare-the-kneighborsregressor-and-linearregression-on-the-boston-housing-dataset">Compare the KNeighborsRegressor and LinearRegression on the boston housing dataset.</h1>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>


<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span>

<span class="k">print</span><span class="p">(</span><span class="s">'X.shape:'</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">linreg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">knnreg</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">linreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Linear Regression Train/Test: </span><span class="si">%.3</span><span class="s">f/</span><span class="si">%.3</span><span class="s">f'</span> <span class="o">%</span>
      <span class="p">(</span><span class="n">linreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
       <span class="n">linreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

<span class="n">knnreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'KNeighborsRegressor Train/Test: </span><span class="si">%.3</span><span class="s">f/</span><span class="si">%.3</span><span class="s">f'</span> <span class="o">%</span>
      <span class="p">(</span><span class="n">knnreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
       <span class="n">knnreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>X.shape: (506, 13)
Linear Regression Train/Test: 0.748/0.684
KNeighborsRegressor Train/Test: 1.000/0.474
</code></pre>
</div>

<p>References:</p>

<p>The content in this post is largely taken from the github repository <a href="https://github.com/amueller/scipy-2017-sklearn">https://github.com/amueller/scipy-2017-sklearn</a></p>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Introduction to Machine Learning with Python</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Introduction to Machine Learning with Python
            
            </li>
            
            <li><a href="mailto:ml.nitmeg@gmail.com">ml.nitmeg@gmail.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/ml.nitmeg@gmail.com"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">ml.nitmeg@gmail.com</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/jekyllrb"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">jekyllrb</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>This is an Introduction to machine Learning using python. We will using some of the most common open source machine packages.</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
