<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Lesson-2: Representation and Visualization of Data</title>
  <meta name="description" content="Representation and Visualization of Data">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/lesson/2017/09/19/Lesson-2-Data-Representation.html">
  <link rel="alternate" type="application/rss+xml" title="Introduction to Machine Learning with Python" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">Introduction to Machine Learning with Python</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/books/">Books</a>
            
          
            
            
          
            
            
            <a class="page-link" href="/resources/">Resources</a>
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Lesson-2: Representation and Visualization of Data</h1>
    <p class="post-meta">
      <time datetime="2017-09-19T01:31:56+05:30" itemprop="datePublished">
        
        Sep 19, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h1 id="representation-and-visualization-of-data">Representation and Visualization of Data</h1>

<p>Machine learning is about fitting models to data; for that reason, we’ll start by
discussing how data can be represented in order to be understood by the computer.</p>

<h2 id="data-in-scikit-learn">Data in scikit-learn</h2>

<p>Data in scikit-learn, with very few exceptions, is assumed to be stored as a
<strong>two-dimensional array</strong>, of shape <code class="highlighter-rouge">[n_samples, n_features]</code>. Many algorithms also accept <code class="highlighter-rouge">scipy.sparse</code> matrices of the same shape.</p>

<ul>
  <li><strong>n_samples:</strong>   The number of samples: each sample is an item to process (e.g. classify).
A sample can be a document, a picture, a sound, a video, an astronomical object,
a row in database or CSV file,
or whatever you can describe with a fixed set of quantitative traits.</li>
  <li><strong>n_features:</strong>  The number of features or distinct traits that can be used to describe each
item in a quantitative manner.  Features are generally real-valued, but may be Boolean or
discrete-valued in some cases.</li>
</ul>

<p>The number of features must be fixed in advance. However it can be very high dimensional
(e.g. millions of features) with most of them being “zeros” for a given sample. This is a case
where <code class="highlighter-rouge">scipy.sparse</code> matrices can be useful, in that they are
much more memory-efficient than NumPy arrays.</p>

<p>As we recall from the previous preliminary section, we represent samples (data points or instances) as rows in the data array, and we store the corresponding features, the “dimensions,” as columns.</p>

<h3 id="a-simple-example-the-iris-dataset">A Simple Example: the Iris Dataset</h3>

<p>As an example of a simple dataset, we’re going to take a look at the iris data stored by scikit-learn.
The data consists of measurements of three different iris flower species.  There are three different species of iris
in this particular dataset as illustrated below:</p>

<p>Iris Setosa
<img src="/images/iris_setosa.jpg" width="50%" /></p>

<p>Iris Versicolor
<img src="/images/iris_versicolor.jpg" width="50%" /></p>

<p>Iris Virginica
<img src="/images/iris_virginica.jpg" width="50%" /></p>

<h3 id="quick-question">Quick Question:</h3>

<p><strong>Let’s assume that we are interested in categorizing new observations; we want to predict whether unknown flowers are  Iris-Setosa, Iris-Versicolor, or Iris-Virginica flowers, respectively. How would we construct such a dataset?</strong>*</p>

<p>Remember: we need a 2D array of size <code class="highlighter-rouge">[n_samples x n_features]</code>.</p>

<ul>
  <li>
    <p>What would the <code class="highlighter-rouge">n_samples</code> refer to?</p>
  </li>
  <li>
    <p>What might the <code class="highlighter-rouge">n_features</code> refer to?</p>
  </li>
</ul>

<h3 id="loading-the-iris-data-with-scikit-learn">Loading the Iris Data with Scikit-learn</h3>

<p>For future experiments with machine learning algorithms, we recommend you to bookmark the <a href="http://archive.ics.uci.edu/ml/">UCI machine learning repository</a>, which hosts many of the commonly used datasets that are useful for benchmarking machine learning algorithms – a very popular resource for machine learning practioners and researchers. Conveniently, some of these datasets are already included in scikit-learn so that we can skip the tedious parts of downloading, reading, parsing, and cleaning these text/CSV files. You can find a list of available datasets in scikit-learn at: http://scikit-learn.org/stable/datasets/#toy-datasets.</p>

<p>For example, scikit-learn has a very straightforward set of data on these iris species.  The data consist of
the following:</p>

<ul>
  <li>
    <p>Features in the Iris dataset:</p>

    <ol>
      <li>sepal length in cm</li>
      <li>sepal width in cm</li>
      <li>petal length in cm</li>
      <li>petal width in cm</li>
    </ol>
  </li>
  <li>
    <p>Target classes to predict:</p>

    <ol>
      <li>Iris Setosa</li>
      <li>Iris Versicolour</li>
      <li>Iris Virginica</li>
    </ol>
  </li>
</ul>

<p><img src="/images/petal_sepal.jpg" alt="Sepal" style="width: 50%;" /></p>

<p>(Image: “Petal-sepal”. Licensed under CC BY-SA 3.0 via Wikimedia Commons - https://commons.wikimedia.org/wiki/File:Petal-sepal.jpg#/media/File:Petal-sepal.jpg)</p>

<p><code class="highlighter-rouge">scikit-learn</code> embeds a copy of the iris CSV file along with a helper function to load it into numpy arrays:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</code></pre>
</div>

<p>The resulting dataset is a <code class="highlighter-rouge">Bunch</code> object: you can see what’s available using
the method <code class="highlighter-rouge">keys()</code>:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">iris</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>dict_keys(['target_names', 'target', 'data', 'feature_names', 'DESCR'])
</code></pre>
</div>

<p>The features of each sample flower are stored in the <code class="highlighter-rouge">data</code> attribute of the dataset:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Number of samples:'</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Number of features:'</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="c"># the sepal length, sepal width, petal length and petal width of the first sample (first flower)</span>
<span class="k">print</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Number of samples: 150
Number of features: 4
[ 5.1  3.5  1.4  0.2]
</code></pre>
</div>

<p>The information about the class of each sample is stored in the <code class="highlighter-rouge">target</code> attribute of the dataset:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>(150, 4)
(150,)
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>  <span class="c"># count how many samples for each target</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>array([50, 50, 50])
</code></pre>
</div>

<p>Using the NumPy’s bincount function (above), we can see that the classes are distributed uniformly in this dataset - there are 50 flowers from each species, where</p>

<ul>
  <li>class 0: Iris-Setosa</li>
  <li>class 1: Iris-Versicolor</li>
  <li>class 2: Iris-Virginica</li>
</ul>

<p>These class names are stored in the last attribute, namely <code class="highlighter-rouge">target_names</code>:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>['setosa' 'versicolor' 'virginica']
</code></pre>
</div>

<p>This data is four dimensional, but we can visualize one or two of the dimensions
at a time using a simple histogram or scatter-plot.  Again, we’ll start by enabling
matplotlib inline mode:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">x_index</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'blue'</span><span class="p">,</span> <span class="s">'red'</span><span class="p">,</span> <span class="s">'green'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)),</span> <span class="n">colors</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">==</span><span class="n">label</span><span class="p">,</span> <span class="n">x_index</span><span class="p">],</span> 
             <span class="n">label</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
             <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">x_index</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p><img src="/images/03.Data_Representation_for_Machine_Learning-Bernard_files/03.Data_Representation_for_Machine_Learning-Bernard_28_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">x_index</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">y_index</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'blue'</span><span class="p">,</span> <span class="s">'red'</span><span class="p">,</span> <span class="s">'green'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">)),</span> <span class="n">colors</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">==</span><span class="n">label</span><span class="p">,</span> <span class="n">x_index</span><span class="p">],</span> 
                <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">==</span><span class="n">label</span><span class="p">,</span> <span class="n">y_index</span><span class="p">],</span>
                <span class="n">label</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
                <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">x_index</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="n">y_index</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<p><img src="/images/03.Data_Representation_for_Machine_Learning-Bernard_files/03.Data_Representation_for_Machine_Learning-Bernard_29_0.png" alt="png" /></p>

<h3 id="an-aside-scatterplot-matrices">An aside: scatterplot matrices</h3>

<p>Instead of looking at the data one plot at a time, a common tool that analysts use is called the <strong>scatterplot matrix</strong>.</p>

<p>Scatterplot matrices show scatter plots between all features in the data set, as well as histograms to show the distribution of each feature.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># use pandas library </span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
    
<span class="n">iris_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">iris_df</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">));</span>
</code></pre>
</div>

<p><img src="/images/03.Data_Representation_for_Machine_Learning-Bernard_files/03.Data_Representation_for_Machine_Learning-Bernard_31_0.png" alt="png" /></p>

<h2 id="other-available-data">Other Available Data</h2>

<p><a href="http://scikit-learn.org/stable/datasets/#dataset-loading-utilities">Scikit-learn makes available a host of datasets for testing learning algorithms</a>.
They come in three flavors:</p>

<ul>
  <li><strong>Packaged Data:</strong> these small datasets are packaged with the scikit-learn installation,
and can be downloaded using the tools in <code class="highlighter-rouge">sklearn.datasets.load_*</code></li>
  <li><strong>Downloadable Data:</strong> these larger datasets are available for download, and scikit-learn
includes tools which streamline this process.  These tools can be found in
<code class="highlighter-rouge">sklearn.datasets.fetch_*</code></li>
  <li><strong>Generated Data:</strong> there are several datasets which are generated from models based on a
random seed.  These are available in the <code class="highlighter-rouge">sklearn.datasets.make_*</code></li>
</ul>

<p>You can explore the available dataset loaders, fetchers, and generators using IPython’s
tab-completion functionality.  After importing the <code class="highlighter-rouge">datasets</code> submodule from <code class="highlighter-rouge">sklearn</code>,
type</p>

<div class="highlighter-rouge"><pre class="highlight"><code>datasets.load_&lt;TAB&gt;
</code></pre>
</div>

<p>or</p>

<div class="highlighter-rouge"><pre class="highlight"><code>datasets.fetch_&lt;TAB&gt;
</code></pre>
</div>

<p>or</p>

<div class="highlighter-rouge"><pre class="highlight"><code>datasets.make_&lt;TAB&gt;
</code></pre>
</div>

<p>to see a list of available functions.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</code></pre>
</div>

<p>Be warned: many of these datasets are quite large, and can take a long time to download!</p>

<p>If you start a download within the IPython notebook
and you want to kill it, you can use ipython’s “kernel interrupt” feature, available in the menu or using
the shortcut <code class="highlighter-rouge">Ctrl-m i</code>.</p>

<p>You can press <code class="highlighter-rouge">Ctrl-m h</code> for a list of all <code class="highlighter-rouge">ipython</code> keyboard shortcuts.</p>

<h2 id="loading-digits-data">Loading Digits Data</h2>

<p>Now we’ll take a look at another dataset, one where we have to put a bit
more thought into how to represent the data.  We can explore the data in
a similar manner as above:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">digits</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>dict_keys(['target_names', 'target', 'data', 'images', 'DESCR'])
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>(1797, 64)
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>[  0.   0.   5.  13.   9.   1.   0.   0.   0.   0.  13.  15.  10.  15.   5.
   0.   0.   3.  15.   2.   0.  11.   8.   0.   0.   4.  12.   0.   0.   8.
   8.   0.   0.   5.   8.   0.   0.   9.   8.   0.   0.   4.  11.   0.   1.
  12.   7.   0.   0.   2.  14.   5.  10.  12.   0.   0.   0.   0.   6.  13.
  10.   0.   0.   0.]
[0 1 2 ..., 8 9 8]
</code></pre>
</div>

<p>The target here is just the digit represented by the data.  The data is an array of
length 64… but what does this data mean?</p>

<p>There’s a clue in the fact that we have two versions of the data array:
<code class="highlighter-rouge">data</code> and <code class="highlighter-rouge">images</code>.  Let’s take a look at them:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>(1797, 64)
(1797, 8, 8)
</code></pre>
</div>

<p>We can see that they’re related by a simple reshaping:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">all</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span> <span class="o">==</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>True
</code></pre>
</div>

<p>Let’s visualize the data.  It’s little bit more involved than the simple scatter-plot
we used above, but we can do it rather quickly.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># set up the figure</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c"># figure size in inches</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<span class="c"># plot the digits: each image is 8x8 pixels</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'nearest'</span><span class="p">)</span>
    <span class="c"># label the image with the target value</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</code></pre>
</div>

<p><img src="/images/03.Data_Representation_for_Machine_Learning-Bernard_files/03.Data_Representation_for_Machine_Learning-Bernard_48_0.png" alt="png" /></p>

<p>We see now what the features mean.  Each feature is a real-valued quantity representing the
darkness of a pixel in an 8x8 image of a hand-written digit.</p>

<p>Even though each sample has data that is inherently two-dimensional, the data matrix flattens
this 2D data into a <strong>single vector</strong>, which can be contained in one <strong>row</strong> of the data matrix.</p>

<h1 id="working-with-the-faces-dataset">working with the faces dataset</h1>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_olivetti_faces</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># fetch the faces data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">fetch_olivetti_faces</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bone</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">)</span> <span class="c"># unique person in the dataset</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,
       34, 35, 36, 37, 38, 39])
</code></pre>
</div>

<p><img src="/images/03.Data_Representation_for_Machine_Learning-Bernard_files/03.Data_Representation_for_Machine_Learning-Bernard_52_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">)</span> <span class="c"># number of samples representing each person</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
       10, 10, 10, 10, 10, 10])
</code></pre>
</div>

<h1 id="see-all-images-in-dataset">See all images in dataset</h1>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># set up the figure</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c"># figure size in inches</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<span class="c"># plot the faces:</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bone</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'nearest'</span><span class="p">)</span>
</code></pre>
</div>

<p><img src="/images/03.Data_Representation_for_Machine_Learning-Bernard_files/03.Data_Representation_for_Machine_Learning-Bernard_55_0.png" alt="png" /></p>

<p>The content in this post is largely taken from the github repository <a href="https://github.com/amueller/scipy-2017-sklearn">https://github.com/amueller/scipy-2017-sklearn</a></p>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Introduction to Machine Learning with Python</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Introduction to Machine Learning with Python
            
            </li>
            
            <li><a href="mailto:ml.nitmeg@gmail.com">ml.nitmeg@gmail.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/ml.nitmeg@gmail.com"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">ml.nitmeg@gmail.com</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/jekyllrb"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">jekyllrb</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>This is an Introduction to machine Learning using python. We will using some of the most common open source machine packages.</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
